{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a081e727",
   "metadata": {},
   "source": [
    "# Amazon SageMaker Canvas fine-tune foundation model\n",
    "\n",
    "This notebook was automatically generated for Amazon SageMaker Canvas model **fine**.The\n",
    "notebook allows you to select a candidate base model, inspect and modify the hyperparameters and perform\n",
    "fine-tuning. Depending on the candidate base model, the fine-tuning is performed by either Amazon SageMaker Autopilot\n",
    "or Amazon Bedrock. The notebook also allows preparing the fine-tuned model and run inference on the same.\n",
    "\n",
    "---\n",
    "\n",
    "## Contents\n",
    "\n",
    "1. [Setup](#1.-Setup)\n",
    "1. [Candidate selection](#2.-Select-text-generation-candidate-to-train)\n",
    "1. [Fine-tune the selected candidate](#3.-Fine-tune-the-selected-candidate)\n",
    "1. [Model metrics](#4.-Model-metrics)\n",
    "1. [Deploy & run inference on the fine-tuned model](#5.-Deploy-&-run-Inference-on-the-fine-tuned-model)\n",
    "1. [Clean up](#6.-Clean-up)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014a3b32",
   "metadata": {},
   "source": [
    "## 1. Setup\n",
    "\n",
    "Before executing the notebook, there are some initial steps required for setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e791f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade sagemaker --quiet\n",
    "!pip install --upgrade --force-reinstall boto3\n",
    "!pip install --upgrade pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2232dc",
   "metadata": {},
   "source": [
    "Here, we use the execution role associated with the current notebook instance as the\n",
    "AWS account role with SageMaker and Bedrock access. It should have necessary permissions,\n",
    "including access to your data in S3. We also initialize SageMaker and Bedrock clients for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8348e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sagemaker, boto3, json\n",
    "from sagemaker.session import Session\n",
    "from pprint import pprint\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "sagemaker_session = Session()\n",
    "aws_role = sagemaker_session.get_caller_identity_arn()\n",
    "aws_region = boto3.Session().region_name\n",
    "\n",
    "bedrock_runtime_client = boto3.client('bedrock-runtime')\n",
    "bedrock_client = boto3.client('bedrock')\n",
    "sagemaker_client = boto3.client(\"sagemaker\")\n",
    "sagemaker_runtime_client = boto3.client('sagemaker-runtime')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8835193e",
   "metadata": {},
   "source": [
    "## 2. Select text generation candidate to train\n",
    "\n",
    "All the base models chosen as part of SageMaker Canvas model setup are included as candidates here. A base model could\n",
    "be a Jumpstart model or a Bedrock proprietary model. Jumpstart models will be fine-tuned through Amazon\n",
    "SageMaker Autopilot while the Bedrock proprietary ones will be fine-tuned through Amazon Bedrock.\n",
    "\n",
    "A candidate is selected by default. You can also update the selected candidate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2bd062c",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates = [\n",
    "    {\n",
    "        \"baseModelType\": \"jumpstart\",\n",
    "        \"baseModelName\": \"Falcon7BInstruct\",\n",
    "        \"hyperparameters\": {\n",
    "            \"epochCount\": \"10\",\n",
    "            \"batchSize\": \"1\",\n",
    "            \"learningRate\": \"0.0002\",\n",
    "            \"learningRateWarmupSteps\": \"1\"\n",
    "        }\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71ab84d",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"> ðŸ’¡ <strong> Available Knobs</strong>\n",
    "Selected candidate can be updated by updating the candidate index.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69694e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_candidate = candidates[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6276712",
   "metadata": {},
   "source": [
    "## 3. Fine tune the selected candidate\n",
    "\n",
    "Fine-tuning refers to the process of customizing a foundation model on custom data to improve its performance for a specific task or domain.\n",
    "\n",
    "<div class=\"alert alert-info\"> ðŸ’¡ <strong> Available Knobs</strong>\n",
    "\n",
    "The recommended hyperparameter values for the selected candidate can be overridden with custom values if required. Uncomment the code and adjust the values. A brief description of each hyperparameter is included below.\n",
    "\n",
    "1. **Epoch count**: The epoch count is the number of times that the model is trained on the entire training set.A larger number of epochs will allow the model to learn more thoroughly, but it may also make it more likely to overfit to the training data. A smaller number of epochs will allow the model to learn less thoroughly, but it may also make it less likely to overfit.\n",
    "1. **Batch Size**: The batch size is the number of training examples that the model is trained on at each iteration. A larger batch size will allow the model to learn more quickly, but it may also require more memory. A smaller batch size will allow the model to learn more slowly, but it may also require less memory.\n",
    "1. **Learning Rate**: The learning rate determines how quickly the model updates its weights during training. A higher learning rate will cause the model to learn more quickly, but it may also make it more likely to overfit to the training data. A lower learning rate will cause the model to learn more slowly, but it may also make it less likely to overfit.\n",
    "1. **Learning Rate warmup steps**: The number of training steps over which the learning rate is gradually increased from a small initial value to a higher target value. This helps the model to learn more quickly at the beginning of training, when it is still trying to figure out the basic structure of the data. As the model learns more, the learning rate is gradually reduced to prevent it from overfitting.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4cbbc4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# selected_candidate[\"hyperparameters\"][\"epochCount\"] = 10\n",
    "# selected_candidate[\"hyperparameters\"][\"batchSize\"] = 1\n",
    "# selected_candidate[\"hyperparameters\"][\"learningRate\"] = 0.0002\n",
    "# selected_candidate[\"hyperparameters\"][\"learningRateWarmupSteps\"] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "293a6e99",
   "metadata": {},
   "source": [
    "Here we setup the fine-tuning job input depending on the candidate's model type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23bc077",
   "metadata": {},
   "outputs": [],
   "source": [
    "if selected_candidate[\"baseModelType\"] == \"jumpstart\":\n",
    "    request = {\n",
    "        \"AutoMLJobName\": f\"fine-{datetime.now():%Y-%m-%d-%H-%M-%S}\"[0:31],\n",
    "        \"AutoMLProblemTypeConfig\": {\n",
    "            \"TextGenerationJobConfig\": {\n",
    "                \"BaseModelName\": selected_candidate[\"baseModelName\"],\n",
    "                \"TextGenerationHyperParameters\": selected_candidate[\"hyperparameters\"],\n",
    "            }\n",
    "        },\n",
    "        \"RoleArn\": aws_role,\n",
    "        \"AutoMLJobInputDataConfig\": [\n",
    "            {\n",
    "                \"ChannelType\": \"training\",\n",
    "                \"DataSource\": {\n",
    "                    \"S3DataSource\": {\n",
    "                        \"S3DataType\": \"S3Prefix\",\n",
    "                        \"S3Uri\": \"s3://sagemaker-us-east-2-390403892280/Canvas/default-20250623T162593/Datasets/0cf01bab-13d0-4050-a6eb-762d5e892ab2/1750785831.467282/autopilot/training\"\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"ChannelType\": \"validation\",\n",
    "                \"DataSource\": {\n",
    "                    \"S3DataSource\": {\n",
    "                        \"S3DataType\": \"S3Prefix\",\n",
    "                        \"S3Uri\": \"s3://sagemaker-us-east-2-390403892280/Canvas/default-20250623T162593/Datasets/0cf01bab-13d0-4050-a6eb-762d5e892ab2/1750785831.467282/autopilot/validation\"\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        ],\n",
    "        \"OutputDataConfig\": {\n",
    "            \"S3OutputPath\": \"s3://sagemaker-us-east-2-390403892280/Training/\"\n",
    "        },\n",
    "        \"Tags\": [{'Key': 'sagemaker:is-canvas-resource', 'Value': 'True'}, {'Key': 'sagemaker:is-canvas-genai-resource', 'Value': 'True'}, {'Key': 'sagemaker:is-created-from-canvas-notebook', 'Value': 'True'}],\n",
    "    }\n",
    "elif selected_candidate[\"baseModelType\"] == \"bedrock\":\n",
    "    request = {\n",
    "        \"baseModelIdentifier\": selected_candidate[\"baseModelName\"],\n",
    "        \"trainingDataConfig\": {\n",
    "            \"s3Uri\": None\n",
    "        },\n",
    "        \"customModelName\": f\"fine-{datetime.now():%Y-%m-%d-%H-%M-%S}\",\n",
    "        \"hyperParameters\": selected_candidate[\"hyperparameters\"],\n",
    "        \"jobName\": f\"fine-{datetime.now():%Y-%m-%d-%H-%M-%S}\",\n",
    "        \"roleArn\": aws_role,\n",
    "        \"outputDataConfig\": {\n",
    "            \"s3Uri\": None\n",
    "        },\n",
    "        \"validationDataConfig\": {\n",
    "            \"validators\": [\n",
    "                {\n",
    "                    \"s3Uri\": None\n",
    "                }\n",
    "            ]\n",
    "        },\n",
    "        \"customModelTags\": [{'key': 'sagemaker:is-canvas-resource', 'value': 'True'}, {'key': 'sagemaker:is-canvas-genai-resource', 'value': 'True'}, {'key': 'sagemaker:is-created-from-canvas-notebook', 'value': 'True'}],\n",
    "        \"jobTags\": [{'key': 'sagemaker:is-canvas-resource', 'value': 'True'}, {'key': 'sagemaker:is-canvas-genai-resource', 'value': 'True'}, {'key': 'sagemaker:is-created-from-canvas-notebook', 'value': 'True'}],\n",
    "    }\n",
    "else:\n",
    "    raise ValueError(\"Unknown model type\")\n",
    "\n",
    "pprint(request)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b07d2db",
   "metadata": {},
   "source": [
    "Now we launch the fine-tuning job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fca9fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "if selected_candidate[\"baseModelType\"] == \"jumpstart\":\n",
    "    response = sagemaker_client.create_auto_ml_job_v2(**request)\n",
    "elif selected_candidate[\"baseModelType\"] == \"bedrock\":\n",
    "    response = bedrock_client.create_model_customization_job(**request)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfbf8ec9",
   "metadata": {},
   "source": [
    "Here we query for the job status. The job needs to completed before we can proceed with the further sections of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba635385",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wait_fine_tuning_job_to_complete():\n",
    "    print(\"Waiting for fine-tuning job to complete\")\n",
    "    while True:\n",
    "        if selected_candidate[\"baseModelType\"] == \"jumpstart\":\n",
    "            job_details = sagemaker_client.describe_auto_ml_job_v2(\n",
    "                    AutoMLJobName=request['AutoMLJobName'])\n",
    "            job_status = job_details[\"AutoMLJobStatus\"]\n",
    "\n",
    "        elif selected_candidate[\"baseModelType\"] == \"bedrock\":\n",
    "            job_details = bedrock_client.get_model_customization_job(\n",
    "                    jobIdentifier=request[\"customModelName\"]\n",
    "            )\n",
    "            job_status = job_details[\"status\"]\n",
    "\n",
    "        if job_status in [\"Completed\", \"Failed\", \"Stopped\"]:\n",
    "            print(f\"\\nJob finished with status: {job_status}\")\n",
    "            break\n",
    "\n",
    "        print(\".\", end=\"\", flush=True)\n",
    "        time.sleep(120)\n",
    "    return job_details, job_status\n",
    "\n",
    "job_details, job_status = wait_fine_tuning_job_to_complete()\n",
    "\n",
    "pprint(f'Base model type: {selected_candidate[\"baseModelType\"]}')\n",
    "pprint(f'Job Status: {job_status}')\n",
    "#pprint(f'Complete Job details: {job_details}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109092a1",
   "metadata": {},
   "source": [
    "## 4. Model metrics\n",
    "\n",
    "In this section, we will fetch training and validation metrics for the fine tuning job. A brief description of the metrics is included below.\n",
    "\n",
    "1. **Training perplexity** is a measure of how well a language model predicts the next word in a sequence of words, given the words that have already been seen. A lower perplexity score indicates that the language model is better at predicting the next word in a sequence of words.\n",
    "1. **Validation perplexity** is a measure of how well a language model predicts the next word in a sequence of words, given the words that have already been seen, on a held-out validation dataset. A lower perplexity score indicates that the language model is better at predicting the next word in a sequence of words.\n",
    "1. **Training loss** is a metric used to evaluate how well a fine-tuned large language model is learning during the training process. The lower the training loss, the better the model is learning.\n",
    "1. **Validation loss** is a metric used to evaluate how well a fine-tuned large language model performs on a held-out dataset of data that was not used to train the model. The lower the validation loss, the better the model is performing.\n",
    "1. **ROUGE (Recall-Oriented Understudy for Gisting Evaluation)** is a metric used to evaluate the quality of summaries generated by a language model. ROUGE is a good measure of how well a system can summarize the main points of a text. This metric is emitted only for jumpstart models.\n",
    "1. **BLEU (Bilingual Evaluation Understudy)** is a metric used to compare a candidate translation of text to one or more reference translations. BLEU is a good measure of how well a system can translate words and phrases accurately. This metric is emitted only for jumpstart models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5490ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_metrics(training_metrics_s3_path, validation_metrics_s3_path):\n",
    "    print(\"Training Metrics\\n\")\n",
    "    print(f'S3 Path: {training_metrics_s3_path}\\n')\n",
    "    df = pd.read_csv(training_metrics_s3_path)\n",
    "    print(df.head(5))\n",
    "    print(\"\\n\\n\")\n",
    "    print(\"Validation Metrics\\n\")\n",
    "    print(f'S3 Path: {validation_metrics_s3_path}\\n')\n",
    "    df = pd.read_csv(validation_metrics_s3_path)\n",
    "    print(df.head(5))\n",
    "\n",
    "def get_best_candidate_training_step_name(sagemaker_autopilot_job_details):\n",
    "    candidate_steps = sagemaker_autopilot_job_details[\"BestCandidate\"][\"CandidateSteps\"]\n",
    "    for candidate_step in candidate_steps:\n",
    "        if candidate_step[\"CandidateStepType\"] == \"AWS::SageMaker::TrainingJob\":\n",
    "            return candidate_step[\"CandidateStepName\"]\n",
    "\n",
    "    raise ValueError(\"No training step found for the best candidate\")\n",
    "\n",
    "def display_bedrock_fine_tuned_model_metrics():\n",
    "    job_details = bedrock_client.get_model_customization_job(\n",
    "        jobIdentifier = request[\"customModelName\"]\n",
    "    )\n",
    "    training_metrics_s3_path = (\n",
    "        f'{job_details[\"outputDataConfig\"][\"s3Uri\"]}'\n",
    "        f'model-customization-job-{job_details[\"jobArn\"].split(\"/\")[-1]}'\n",
    "        '/training_artifacts/step_wise_training_metrics.csv'\n",
    "    )\n",
    "    validation_metrics_s3_path = (\n",
    "        f'{job_details[\"outputDataConfig\"][\"s3Uri\"]}'\n",
    "        f'model-customization-job-{job_details[\"jobArn\"].split(\"/\")[-1]}'\n",
    "        '/validation_artifacts/post_fine_tuning_validation/validation/validation_metrics.csv'\n",
    "    )\n",
    "\n",
    "    display_metrics(training_metrics_s3_path, validation_metrics_s3_path)\n",
    "\n",
    "\n",
    "def display_autopilot_fine_tuned_model_metrics():\n",
    "    job_details = sagemaker_client.describe_auto_ml_job_v2(\n",
    "        AutoMLJobName=request['AutoMLJobName']\n",
    "    )\n",
    "    training_step_name = get_best_candidate_training_step_name(job_details)\n",
    "    training_metrics_s3_path = (\n",
    "        f'{job_details[\"OutputDataConfig\"][\"S3OutputPath\"]}'\n",
    "        f'{request[\"AutoMLJobName\"]}'\n",
    "        f'/{training_step_name}'\n",
    "        '/train_metrics.csv'\n",
    "    )\n",
    "    validation_metrics_s3_path = (\n",
    "        f'{job_details[\"OutputDataConfig\"][\"S3OutputPath\"]}'\n",
    "        f'{request[\"AutoMLJobName\"]}'\n",
    "        f'/{training_step_name}'\n",
    "        '/validation_metrics.csv'\n",
    "    )\n",
    "\n",
    "    display_metrics(training_metrics_s3_path, validation_metrics_s3_path)\n",
    "\n",
    "\n",
    "if selected_candidate[\"baseModelType\"] == \"jumpstart\":\n",
    "    display_autopilot_fine_tuned_model_metrics()\n",
    "elif selected_candidate[\"baseModelType\"] == \"bedrock\":\n",
    "    display_bedrock_fine_tuned_model_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ec98ad",
   "metadata": {},
   "source": [
    "## 5. Deploy & run Inference on the fine-tuned model\n",
    "\n",
    "We now want to use the model to perform inference. For a model fine-tuned through Amazon Bedrock, we will create a provisioned model for inference. A model fine-tuned through SageMaker Autopilot will be deployed to a real-time SageMaker endpoint for performing inference.\n",
    "\n",
    "To begin with, we will define a few useful functions here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ec2405",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_provisioned_model_throughput(modelId):\n",
    "    provisioned_model_name = f\"fine-provisioned-{datetime.now():%Y-%m-%d-%H-%M-%S}\"\n",
    "    response = bedrock_client.create_provisioned_model_throughput(\n",
    "        modelUnits=1,\n",
    "        provisionedModelName=provisioned_model_name,\n",
    "        modelId=modelId,\n",
    "        tags=[{'key': 'sagemaker:is-canvas-resource', 'value': 'True'}, {'key': 'sagemaker:is-canvas-genai-resource', 'value': 'True'}, {'key': 'sagemaker:is-created-from-canvas-notebook', 'value': 'True'}],\n",
    "    )\n",
    "    pprint(f\"Created provisioned model {response}\")\n",
    "    return response[\"provisionedModelArn\"]\n",
    "\n",
    "\n",
    "def create_sagemaker_model(automl_job_details):\n",
    "    inference_containers = automl_job_details[\"BestCandidate\"][\"InferenceContainerDefinitions\"][\"GPU\"]\n",
    "    model_name = f\"fine-sm-model-{datetime.now():%Y-%m-%d-%H-%M-%S}\"\n",
    "    response = sagemaker_client.create_model(\n",
    "        ModelName=model_name,\n",
    "        ExecutionRoleArn=aws_role,\n",
    "        Containers=inference_containers,\n",
    "    )\n",
    "    pprint(f\"Created Sagemaker model {response}\")\n",
    "    return model_name\n",
    "\n",
    "\n",
    "def create_sagemaker_endpoint_config(sagemaker_model_name):\n",
    "    endpoint_config_name = f\"fine-ec-{datetime.now():%Y-%m-%d-%H-%M-%S}\"\n",
    "    production_variant_config = dict(\n",
    "        InstanceType=\"ml.g5.24xlarge\",\n",
    "        InitialInstanceCount=1,\n",
    "        ModelName=sagemaker_model_name,\n",
    "        InitialVariantWeight=1.0,\n",
    "        ModelDataDownloadTimeoutInSeconds=3600,\n",
    "        ContainerStartupHealthCheckTimeoutInSeconds=3600,\n",
    "        VariantName=f\"production-variant-{datetime.now():%Y-%m-%d-%H-%M-%S}\",\n",
    "    )\n",
    "\n",
    "    response = sagemaker_client.create_endpoint_config(\n",
    "        EndpointConfigName=endpoint_config_name,\n",
    "        ProductionVariants=[production_variant_config],\n",
    "        Tags=[{'Key': 'sagemaker:is-canvas-resource', 'Value': 'True'}, {'Key': 'sagemaker:is-canvas-genai-resource', 'Value': 'True'}, {'Key': 'sagemaker:is-created-from-canvas-notebook', 'Value': 'True'}],\n",
    "    )\n",
    "    pprint(f\"Created endpoint config {response}\")\n",
    "    return endpoint_config_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a2e43d",
   "metadata": {},
   "source": [
    "Here, we create the resources for inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73150c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_endpoint_name = None\n",
    "bedrock_provisioned_model_id = None\n",
    "\n",
    "if selected_candidate[\"baseModelType\"] == \"jumpstart\":\n",
    "    job_details = sagemaker_client.describe_auto_ml_job_v2(\n",
    "        AutoMLJobName=request['AutoMLJobName']\n",
    "    )\n",
    "    sm_model_name = create_sagemaker_model(job_details)\n",
    "    sm_endpoint_config = create_sagemaker_endpoint_config(sm_model_name)\n",
    "    sagemaker_endpoint_name = f\"fine-sm-endpoint-{datetime.now():%Y-%m-%d-%H-%M-%S}\"\n",
    "\n",
    "    response = sagemaker_client.create_endpoint(\n",
    "        EndpointName=sagemaker_endpoint_name, \n",
    "        EndpointConfigName=sm_endpoint_config,\n",
    "        Tags=[{'Key': 'sagemaker:is-canvas-resource', 'Value': 'True'}, {'Key': 'sagemaker:is-canvas-genai-resource', 'Value': 'True'}, {'Key': 'sagemaker:is-created-from-canvas-notebook', 'Value': 'True'}],\n",
    ")\n",
    "    pprint(f\"\\nCreated Endpoint: {response}\")\n",
    "elif selected_candidate[\"baseModelType\"] == \"bedrock\":\n",
    "    bedrock_provisioned_model_id = create_provisioned_model_throughput(\n",
    "        request['customModelName'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb8f8c1",
   "metadata": {},
   "source": [
    "Here we describe the inference resource to check if it is \"In Service\". The status should be \"In Service\" before proceeding with the rest of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434c462f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wait_for_inference_resource_in_service():\n",
    "    print(\"Waiting for inference resource to be ready\")\n",
    "    while True:\n",
    "        if sagemaker_endpoint_name:\n",
    "            response = sagemaker_client.describe_endpoint(\n",
    "                EndpointName=sagemaker_endpoint_name)\n",
    "            status = response[\"EndpointStatus\"]\n",
    "        elif bedrock_provisioned_model_id:\n",
    "            response = bedrock_client.get_provisioned_model_throughput(\n",
    "                provisionedModelId=bedrock_provisioned_model_id\n",
    "            )\n",
    "            status = response[\"status\"]\n",
    "\n",
    "        if status in [\"InService\", \"Failed\"]:\n",
    "            print(f\"Inference resource creation completed with status: {status}\")\n",
    "            break\n",
    "        print(\".\", end=\"\", flush=True)\n",
    "        time.sleep(30)\n",
    "\n",
    "\n",
    "wait_for_inference_resource_in_service()\n",
    "pprint(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b069082b",
   "metadata": {},
   "source": [
    "We can now send data to the endpoint to get inferences in real time. This step invokes the endpoint with included sample data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0687f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_sagemaker_input_payload():\n",
    "    # base model name is defined in https://docs.aws.amazon.com/sagemaker/latest/dg/autopilot-llms-finetuning-models.html#autopilot-llms-finetuning-supported-llms\n",
    "    base_model_name = selected_candidate[\"baseModelName\"]\n",
    "    if \"MPT\" in base_model_name:\n",
    "        return {\n",
    "            \"text_inputs\": \"What is AWS?\",\n",
    "            \"max_length\": 50,\n",
    "        }\n",
    "    elif \"Falcon\" in base_model_name:\n",
    "        return {\n",
    "            \"inputs\": \"What is AWS\",\n",
    "            \"parameters\": {\n",
    "                \"max_new_tokens\": 50,\n",
    "            }\n",
    "        }\n",
    "    elif any(model in base_model_name for model in [\"Dolly\", \"Flan\"]):\n",
    "        return {\n",
    "            \"text_inputs\": \"What is AWS\",\n",
    "            \"max_new_tokens\": 50,\n",
    "        }\n",
    "    else:\n",
    "        raise ValueError(\"Unrecognized base model name\")\n",
    "\n",
    "\n",
    "def invoke_sagemaker_endpoint():\n",
    "    body = json.dumps(build_sagemaker_input_payload()).encode('utf-8')\n",
    "    response = sagemaker_runtime_client.invoke_endpoint(\n",
    "        Body=body,\n",
    "        EndpointName=sagemaker_endpoint_name,\n",
    "        Accept='application/json',\n",
    "        ContentType='application/json',\n",
    "    )\n",
    "    print(response.get('Body').read())\n",
    "\n",
    "\n",
    "def invoke_bedrock_provisioned_model():\n",
    "    body = json.dumps(\n",
    "        {\"inputText\": \"What is AWS?\"}\n",
    "    )\n",
    "\n",
    "    response = bedrock_runtime_client.invoke_model(\n",
    "        body=body,\n",
    "        modelId=bedrock_provisioned_model_id,\n",
    "        accept='application/json',\n",
    "        contentType='application/json'\n",
    "    )\n",
    "    print(response.get('body').read())\n",
    "\n",
    "\n",
    "if selected_candidate[\"baseModelType\"] == \"jumpstart\":\n",
    "    invoke_sagemaker_endpoint()\n",
    "elif selected_candidate[\"baseModelType\"] == \"bedrock\":\n",
    "    invoke_bedrock_provisioned_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52785ae8",
   "metadata": {},
   "source": [
    "## 6. Clean up\n",
    "\n",
    "Here we clean-up the inference resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00106f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if bedrock_provisioned_model_id:\n",
    "    response = bedrock_client.delete_provisioned_model_throughput(\n",
    "        provisionedModelId=bedrock_provisioned_model_id\n",
    "    )\n",
    "\n",
    "if sagemaker_endpoint_name:\n",
    "    response = sagemaker_client.delete_endpoint(\n",
    "        EndpointName=sagemaker_endpoint_name\n",
    "    )\n",
    "\n",
    "pprint(f\"Completed clean-up: {response}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}